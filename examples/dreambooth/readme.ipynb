{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from huggingface_hub import snapshot_download\n",
    "\n",
    "# local_dir = \"./dog\"\n",
    "# snapshot_download(\n",
    "#     \"diffusers/dog-example\",\n",
    "#     local_dir=local_dir, repo_type=\"dataset\",\n",
    "#     ignore_patterns=\".gitattributes\",\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# single inference "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from diffusers import StableDiffusionPipeline\n",
    "import torch\n",
    "\n",
    "model_id = \"/home/paper/diffusers/examples/dreambooth/trained_ckp/starbucks-2-1\"\n",
    "pipe = StableDiffusionPipeline.from_pretrained(model_id, torch_dtype=torch.float16).to(\"cuda\")\n",
    "\n",
    "prompt = \"A photo of starbucks mug on a table\"\n",
    "# prompt = \"A Starbucks mug sits on a table, surrounded by a cozy atmosphere and the aroma of freshly brewed coffee.\"\n",
    "image = pipe(prompt, num_inference_steps=50, guidance_scale=7.5).images[0]\n",
    "\n",
    "# image.save(\"dog-bucket.png\")\n",
    "image.save(\"./inference/starbucks/starbuck-2-1_on_table_0.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# multi prompts inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2481635648b542f0ae4b5cac951d8b6a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ab46b000c96441ef8aa64677f741b448",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "adc11f39c622402db7103e563c7902d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4a778247532c4deb8a191c9d264ea8c8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "06e95210a982499c843d370607426eef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:24, 24.95s/it]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3772d74592414ac78c5295b2f6714db2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cdbbbcb0f6f543d388636e750a8f5ccf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3e032ca2e77f40db8b596caf4029d53b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b8ad66db24e44f29ebe977033116324",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3dd707e78ff04ee098142e16e1ab5954",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2it [00:48, 24.04s/it]\n"
     ]
    }
   ],
   "source": [
    "from diffusers import StableDiffusionPipeline\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "\n",
    "model_id = \"/home/paper/diffusers/examples/dreambooth/trained_ckp/lindanx\"\n",
    "pipe = StableDiffusionPipeline.from_pretrained(model_id, torch_dtype=torch.float16).to(\"cuda\")\n",
    "\n",
    "prompts = [\"A photo of lindanx playing basketball.\",\n",
    "           \"A photo of lindanx walking along the street.\",\n",
    "        ]\n",
    "# prompts = [\"A Starbucks mug sits on a table, surrounded by a cozy atmosphere and the aroma of freshly brewed coffee.\",\n",
    "#            \"On a table, a Starbucks mug is placed, exuding a delightful coffee fragrance that fills the air.\",\n",
    "#            \"This image showcases a Starbucks mug resting on a cute table, with its rich aroma creating a sense of tranquility.\",\n",
    "#            \"A Starbucks mug finds repose on a table, adorned with intricate patterns and vibrant colors, making it an eye-catching centerpiece.\",\n",
    "#            \"A steaming Starbucks coffee cup is placed on a charming table, radiating warmth and energizing vibes.\",\n",
    "#            \"In this heartwarming scene, a Starbucks mug graces a table, offering a moment of pure enjoyment.\",\n",
    "#            \"The Starbucks mug on the table emits a strong coffee aroma, accompanied by warm lighting, creating a delightful ambiance.\",\n",
    "#            \"In this captivating setting, a Starbucks mug calmly rests on a table, providing a moment of comfort and pleasure.\",\n",
    "#            \"A Starbucks mug is delicately placed on a table, blending intricate textures and soft hues to create a visually pleasing experience.\",\n",
    "#            \"This photo showcases a Starbucks mug placed on a table, forming a vibrant scene filled with coziness and warmth.\"]\n",
    "\n",
    "for i, prompt in tqdm(enumerate(prompts)):\n",
    "    for infer in range(5):\n",
    "        image = pipe(prompt, num_inference_steps=50, guidance_scale=7.5).images[0]\n",
    "        image.save(\"./inference/lindan/meixi_win_p{}_i{}.png\".format(i, infer))\n",
    "# image = pipe(prompt, num_inference_steps=50, guidance_scale=7.5).images[0]\n",
    "\n",
    "# image.save(\"dog-bucket.png\")\n",
    "# image.save(\"./inference/starbucks/starbuck_on_table_2.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "video_path = \"/home/paper/AIGC/result/background_beach.mp4\"\n",
    "try:\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "    i = 1\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if ret == True:\n",
    "            frame = cv2.resize(frame,(1280, 720))\n",
    "            cv2.imwrite(\"/home/paper/AIGC/result/interview-background/{:08d}.png\".format(i), frame)\n",
    "            i += 1\n",
    "        else:\n",
    "            break\n",
    "except (OSError, TypeError, ValueError, KeyError, SyntaxError) as e:\n",
    "    print(\"read_frame_source:{} error. {}\\n\".format(video_path, str(e)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "图片转视频"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torchvision\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "frame_names = os.listdir(\"./ref_videos/guanggao_edit/\")\n",
    "frame_names.sort()\n",
    "\n",
    "frames_path = [os.path.join(\"./ref_videos/guanggao_edit/\", frame) for frame in frame_names[:34]]\n",
    "frames = []\n",
    "output_path = \"/home/paper/AIGC/test_sample/guanggao_edit.mp4\"\n",
    "for frame in frames_path:\n",
    "    frames.append(np.asarray(Image.open(frame)))\n",
    "frames = torch.from_numpy(np.asarray(frames))\n",
    "if not os.path.exists(os.path.dirname(output_path)):\n",
    "    os.makedirs(os.path.dirname(output_path))\n",
    "torchvision.io.write_video(output_path, frames, fps=5, video_codec=\"libx264\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# 读取原始图像和修改后的图像\n",
    "original_image = cv2.imread(\"./ref_videos/guanggao/00000001.png\")\n",
    "modified_image = cv2.imread(\"./ref_videos/guanggao_edit/00000001.png\")\n",
    "\n",
    "# 将图像转换为NumPy数组\n",
    "original_array = np.array(original_image)\n",
    "# origin_size = (original_array.shape[1], original_array.shape[0])\n",
    "# modified_image= cv2.resize(modified_image, origin_size)\n",
    "modified_array = np.array(modified_image)\n",
    "\n",
    "# 计算差异\n",
    "difference_array = np.abs(original_array - modified_array)\n",
    "\n",
    "# 设定阈值\n",
    "threshold = 50\n",
    "\n",
    "# 根据阈值创建掩码\n",
    "mask = np.where(difference_array > threshold, 255, 0).astype(np.uint8)\n",
    "# cv2.imwrite(\"./ref_videos/guanggao_edit/mask.png\", mask)\n",
    "mask = cv2.imread(\"./ref_videos/guanggao_edit/mask.png\", -1)\n",
    "\n",
    "# painted_mask = cv2.bitwise_and(modified_image, modified_image, mask=cv2.cvtColor(mask, cv2.COLOR_BGR2GRAY))\n",
    "painted_mask = cv2.bitwise_and(modified_image, modified_image, mask=mask)\n",
    "\n",
    "cv2.imwrite(\"./ref_videos/guanggao_edit/patined_mask_01.png\", painted_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "new_mask = cv2.imread(\"/home/paper/AIGC/test_sample/xiaohuangren_mask.png\", -1)\n",
    "origin_mask = cv2.imread(\"/home/paper/AIGC/test_sample/dogmug_mask.png\", -1)\n",
    "\n",
    "# merge two masks\n",
    "mask = cv2.bitwise_or(new_mask, origin_mask)\n",
    "\n",
    "origin_images = os.listdir(\"./ref_videos/guanggao/\")\n",
    "origin_images.sort()\n",
    "origin_images_path = [os.path.join(\"./ref_videos/guanggao/\", image) for image in origin_images]\n",
    "# 读取原始图像和覆盖图像\n",
    "modified_image = cv2.imread(\"/home/paper/AIGC/test_sample/guanggao_xiaohuangren_resize.png\")\n",
    "for i, image in tqdm(enumerate(origin_images_path)):\n",
    "\n",
    "    original_image = cv2.imread(image)\n",
    "    \n",
    "    # original_image = cv2.imread(\"./ref_videos/guanggao/00000002.png\")\n",
    "    foreground = mask==0\n",
    "\n",
    "    # 将原始图像中的对应区域替换为另一张图像\n",
    "    # result = cv2.bitwise_and(original_image, original_image, mask=mask)\n",
    "    # replacement_image = cv2.imread(\"replacement.jpg\")\n",
    "\n",
    "    mask_color = cv2.bitwise_and(modified_image, modified_image, mask=mask)\n",
    "    origin_foreground = cv2.bitwise_and(original_image, original_image, mask=foreground.astype('uint8'))\n",
    "\n",
    "\n",
    "    result = cv2.bitwise_or(origin_foreground, mask_color)\n",
    "\n",
    "\n",
    "\n",
    "    # 显示结果\n",
    "    cv2.imwrite(\"./ref_videos/guanggao_xiaohuangren/{:08d}.png\".format(i+1), result)\n",
    "    cv2.imwrite(\"/home/paper/AIGC/result/gt_mask/xiaohuangren_merge/{:08d}.png\".format(i+1), result)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# background change\n",
    "import cv2\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "\n",
    "origin_images = os.listdir(\"/home/paper/AIGC/result/originimages/kunkun_interview.mp4/\")\n",
    "origin_images.sort()\n",
    "origin_images_path = [os.path.join(\"/home/paper/AIGC/result/originimages/kunkun_interview.mp4/\", image) for image in origin_images]\n",
    "\n",
    "masks = os.listdir(\"/home/paper/AIGC/result/gt_mask/kunkun_interview/\")\n",
    "masks.sort()\n",
    "masks_path = [os.path.join(\"/home/paper/AIGC/result/gt_mask/kunkun_interview/\", mask) for mask in masks]\n",
    "# 读取原始图像和覆盖图像\n",
    "\n",
    "\n",
    "modified_images = os.listdir(\"/home/paper/AIGC/result/interview-background/\")\n",
    "modified_images.sort()\n",
    "modified_images_path = [os.path.join(\"/home/paper/AIGC/result/interview-background/\", image) for image in modified_images]\n",
    "background_id = 0\n",
    "for i, image in tqdm(enumerate(origin_images_path)):\n",
    "    mask = cv2.imread(masks_path[i],-1)\n",
    "    original_image = cv2.imread(image)\n",
    "    modified_image = cv2.imread(modified_images_path[background_id])\n",
    "    # original_image = cv2.imread(\"./ref_videos/guanggao/00000002.png\")\n",
    "    background = mask==0\n",
    "\n",
    "    # 将原始图像中的对应区域替换为另一张图像\n",
    "    # result = cv2.bitwise_and(original_image, original_image, mask=mask)\n",
    "    # replacement_image = cv2.imread(\"replacement.jpg\")\n",
    "\n",
    "    mask_color = cv2.bitwise_and(modified_image, modified_image, mask=background.astype('uint8'))\n",
    "    origin_foreground = cv2.bitwise_and(original_image, original_image, mask=mask)\n",
    "\n",
    "\n",
    "    result = cv2.bitwise_or(origin_foreground, mask_color)\n",
    "    if background_id < len(modified_images_path)-1:\n",
    "        background_id+=1\n",
    "    else:\n",
    "        background_id = 0\n",
    "\n",
    "\n",
    "    # 显示结果\n",
    "    cv2.imwrite(\"/home/paper/AIGC/result/kunkun_background/{:08d}.png\".format(i+1), result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "# 显示结果\n",
    "cv2.imwrite(\"./ref_videos/guanggao_edit/00000002_foreground.png\", origin_foreground)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "cv2.imwrite(\"./ref_videos/guanggao_edit/00000002.png\", result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ads",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
